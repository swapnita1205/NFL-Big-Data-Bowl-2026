{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":114239,"databundleVersionId":14210809,"sourceType":"competition"},{"sourceId":261649277,"sourceType":"kernelVersion"},{"sourceId":658223,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":497636,"modelId":512958}],"dockerImageVersionId":31193,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        continue\n        # print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:21:27.484836Z","iopub.execute_input":"2025-11-23T19:21:27.485065Z","iopub.status.idle":"2025-11-23T19:21:29.329726Z","shell.execute_reply.started":"2025-11-23T19:21:27.485047Z","shell.execute_reply":"2025-11-23T19:21:29.328991Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# functions","metadata":{}},{"cell_type":"code","source":"import os\n\n# üß© Only the essential PyG wheels (no internet required)\ncore_wheels = [\n    \"pyg_lib-0.4.0+pt26cu124-cp311-cp311-linux_x86_64.whl\",\n    \"torch_scatter-2.1.2+pt26cu124-cp311-cp311-linux_x86_64.whl\",\n    \"torch_sparse-0.6.18+pt26cu124-cp311-cp311-linux_x86_64.whl\",\n    \"torch_cluster-1.6.3+pt26cu124-cp311-cp311-linux_x86_64.whl\",\n    \"torch_spline_conv-1.2.2+pt26cu124-cp311-cp311-linux_x86_64.whl\",\n    \"torch_geometric-2.6.1-py3-none-any.whl\"\n]\n\nfor whl in core_wheels:\n    path = f\"/kaggle/usr/lib/torch_geometric/pyg_wheels/{whl}\"  # adjust folder name if needed\n    print(\"Installing:\", os.path.basename(path))\n    os.system(f\"pip install --no-deps {path} -q\")\n\nimport sys\nsys.path = [p for p in sys.path if \"usr/lib/torch_geometric\" not in p]\n\nimport torch, torch_geometric\nfrom torch_geometric.nn import GATv2Conv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:21:29.330586Z","iopub.execute_input":"2025-11-23T19:21:29.330941Z","iopub.status.idle":"2025-11-23T19:21:52.138394Z","shell.execute_reply.started":"2025-11-23T19:21:29.330915Z","shell.execute_reply":"2025-11-23T19:21:52.137566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# üöÄ FULL PIPELINE: From raw tracking ‚Üí temporal embeddings\n# ============================================================\nimport pandas as pd\nimport numpy as np\nimport glob\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\n\n# ============================================================\n# 1Ô∏è‚É£ Normalization\n# ============================================================\ndef normalize_field_direction(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()\n    mask_left = df[\"play_direction\"].str.lower() == \"left\"\n\n    # Flip x\n    for col in [\"x\", \"ball_land_x\"]:\n        if col in df.columns:\n            df.loc[mask_left, col] = 120 - df.loc[mask_left, col]\n\n    # Flip angles\n    for ang_col in [\"o\", \"dir\"]:\n        if ang_col in df.columns:\n            df.loc[mask_left, ang_col] = (df.loc[mask_left, ang_col] + 180) % 360\n\n    # Center y around midline (26.65)\n    for col in [\"y\", \"ball_land_y\"]:\n        if col in df.columns:\n            df[col] = df[col] - 26.65\n\n    return df\n\n# ============================================================\n# 4Ô∏è‚É£ Temporal Encoder (GRU / Transformer)\n# ============================================================\nclass TemporalTransformer(nn.Module):\n    def __init__(self, in_dim=8, d_model=128, n_heads=4, n_layers=2, dropout=0.1):\n        super().__init__()\n\n        self.input_proj = nn.Linear(in_dim, d_model)\n\n        self.pos_emb = nn.Parameter(torch.randn(1, 60, d_model))   # K up to 60\n\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=d_model,\n            nhead=n_heads,\n            dim_feedforward=d_model*4,\n            dropout=dropout,\n            batch_first=True,\n            norm_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=n_layers)\n\n    def forward(self, x):\n        # x : (P, K, F)\n        P,K,F = x.shape\n\n        x = self.input_proj(x)\n\n        # add positional embeddings: truncate or expand\n        pos = self.pos_emb[:, :K, :]\n\n        x = x + pos\n\n        out = self.encoder(x)       # (P,K,D)\n\n        # take last token\n        return out[:, -1, :]        # (P,D)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:21:52.140152Z","iopub.execute_input":"2025-11-23T19:21:52.140588Z","iopub.status.idle":"2025-11-23T19:21:52.148940Z","shell.execute_reply.started":"2025-11-23T19:21:52.140569Z","shell.execute_reply":"2025-11-23T19:21:52.148257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.neighbors import NearestNeighbors\nfrom tqdm import tqdm\n\ndef build_interaction_graphs(df_input: pd.DataFrame, K: int = 6):\n    \"\"\"\n    Build K-NN interaction graphs per play at the throw frame.\n    Each graph connects every player to K nearest neighbors\n    with edge features [dx, dy, dvx, dvy, ally_flag].\n\n    Returns\n    -------\n    dict[(game_id, play_id)] = {\n        \"nodes\": pd.DataFrame of player features,\n        \"edges\": pd.DataFrame of edge features\n    }\n    \"\"\"\n\n    df = df_input.copy()\n\n    # ------------------------------------------------------------------\n    # üß≠ 1Ô∏è‚É£ Ensure velocity columns exist\n    # ------------------------------------------------------------------\n    if \"vx\" not in df.columns or \"vy\" not in df.columns:\n        df = df.sort_values([\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"]).copy()\n        df[\"vx\"] = df.groupby([\"game_id\", \"play_id\", \"nfl_id\"])[\"x\"].diff().fillna(0)\n        df[\"vy\"] = df.groupby([\"game_id\", \"play_id\", \"nfl_id\"])[\"y\"].diff().fillna(0)\n\n    # ------------------------------------------------------------------\n    # üïê 2Ô∏è‚É£ Extract throw frame (last frame of input for each player)\n    # ------------------------------------------------------------------\n    throw_frame = (\n        df.groupby([\"game_id\", \"play_id\", \"nfl_id\"], group_keys=False)\n          .apply(lambda g: g.tail(1))\n          .reset_index(drop=True)\n    )\n\n    # ------------------------------------------------------------------\n    # üß© 3Ô∏è‚É£ Build graph per play\n    # ------------------------------------------------------------------\n    graphs = {}\n    plays = throw_frame.groupby([\"game_id\", \"play_id\"])\n\n    for (gid, pid), play_df in tqdm(plays, desc=\"Building KNN graphs per play\"):\n\n        # node features (one per player)\n        nodes = play_df[\n            [\"nfl_id\", \"x\", \"y\", \"vx\", \"vy\", \"player_side\", \"player_role\"]\n        ].reset_index(drop=True)\n\n        coords = nodes[[\"x\", \"y\"]].values\n\n        if len(nodes) < 2:\n            continue  # skip incomplete plays\n\n        # Fit KNN (K+1 to include self, drop self edge later)\n        nbrs = NearestNeighbors(\n            n_neighbors=min(K + 1, len(nodes)),\n            algorithm=\"ball_tree\"\n        ).fit(coords)\n        distances, indices = nbrs.kneighbors(coords)\n\n        edge_records = []\n        for i, nbr_idxs in enumerate(indices):\n            for j in nbr_idxs[1:]:  # skip self\n                src = nodes.iloc[i]\n                dst = nodes.iloc[j]\n                dx  = dst[\"x\"]  - src[\"x\"]\n                dy  = dst[\"y\"]  - src[\"y\"]\n                dvx = dst[\"vx\"] - src[\"vx\"]\n                dvy = dst[\"vy\"] - src[\"vy\"]\n\n                # NEW FEATURES\n                dist = np.sqrt(dx*dx + dy*dy + 1e-6)        # distance magnitude\n                dv   = np.sqrt(dvx*dvx + dvy*dvy + 1e-6)    # relative speed magnitude\n                bearing = np.arctan2(dy, dx)\n                cos_bear = np.cos(bearing)\n                sin_bear = np.sin(bearing)\n\n                edge_records.append({\n                    \"src_id\": src[\"nfl_id\"],\n                    \"dst_id\": dst[\"nfl_id\"],\n                    \"dx\": dx,\n                    \"dy\": dy,\n                    \"dvx\": dvx,\n                    \"dvy\": dvy,\n\n                    # NEW\n                    \"dist\": dist,\n                    \"dv\": dv,\n                    \"cos_bear\": cos_bear,\n                    \"sin_bear\": sin_bear,\n\n                    \"ally_flag\": 1 if src[\"player_side\"] == dst[\"player_side\"] else 0\n                })\n\n\n        edges = pd.DataFrame(edge_records)\n        graphs[(gid, pid)] = {\"nodes\": nodes, \"edges\": edges}\n\n    return graphs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:21:52.149758Z","iopub.execute_input":"2025-11-23T19:21:52.150004Z","iopub.status.idle":"2025-11-23T19:21:52.780794Z","shell.execute_reply.started":"2025-11-23T19:21:52.149980Z","shell.execute_reply":"2025-11-23T19:21:52.780156Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SpatialTransformer(nn.Module):\n    def __init__(self, d_model=128, n_heads=4, n_layers=2, dropout=0.1):\n        super().__init__()\n\n        layer = nn.TransformerEncoderLayer(\n            d_model=d_model,\n            nhead=n_heads,\n            dim_feedforward=d_model*4,\n            dropout=dropout,\n            batch_first=True,\n            norm_first=True\n        )\n        self.encoder = nn.TransformerEncoder(layer, num_layers=n_layers)\n\n        # project edge_attr ‚Üí attention bias\n        self.edge_proj = nn.Linear(9, d_model)\n\n    def forward(self, h_nodes, edge_index, edge_attr):\n        \"\"\"\n        h_nodes    : (P,D)\n        edge_index : (2,E)\n        edge_attr  : (E,9)\n        We convert edges ‚Üí full (P,P,d_model) bias matrix.\n        \"\"\"\n\n        P = h_nodes.size(0)\n        device = h_nodes.device\n\n        # build full pairwise bias matrix\n        bias = torch.zeros(P, P, h_nodes.size(1), device=device)\n\n        src, dst = edge_index\n        e = self.edge_proj(edge_attr)         # (E,D)\n        bias[src, dst] = e                    # direct fill-in\n\n        # convert to additive attention bias\n        # flatten into (1,P,P,D)\n        bias = bias.unsqueeze(0)\n\n        # Transformer encoder supports \"src_mask\" but not arbitrary bias.\n        # So we fold bias into embeddings:\n        h = h_nodes.unsqueeze(0)              # (1,P,D)\n        h = h + bias.mean(dim=2)              # aggregate bias per node\n\n        h = self.encoder(h)                   # (1,P,D)\n\n        return h.squeeze(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:21:52.781600Z","iopub.execute_input":"2025-11-23T19:21:52.781996Z","iopub.status.idle":"2025-11-23T19:21:52.788181Z","shell.execute_reply.started":"2025-11-23T19:21:52.781968Z","shell.execute_reply":"2025-11-23T19:21:52.787483Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# ============================================================\n# üß© 3.3 Role-Specific Adapter Module\n# ============================================================\n\nclass RoleSpecificAdapters(nn.Module):\n    \"\"\"\n    Each player_role (e.g., Targeted WR, Coverage DB, Passer, Other)\n    gets its own small MLP adapter that reshapes the 128-D context\n    embedding into a role-specialized representation.\n\n    Input : h_context  ‚Üí (N_players, embed_dim)\n            role_ids   ‚Üí (N_players,)  integers 0..N_roles-1\n    Output: h_adapted  ‚Üí (N_players, embed_dim)\n    \"\"\"\n    def __init__(self, embed_dim=128, hidden_dim=128, role_names=None):\n        super().__init__()\n        if role_names is None:\n            role_names = [\"Targeted Receiver\", \"Defensive Coverage\", \"Passer\", \"Other Route Runner\"]\n        self.role_names = role_names\n        self.n_roles = len(role_names)\n\n        # small MLP adapter per role\n        self.adapters = nn.ModuleDict({\n            name: nn.Sequential(\n                nn.Linear(embed_dim, hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, embed_dim),\n                nn.LayerNorm(embed_dim)\n            )\n            for name in role_names\n        })\n\n        # shared fallback (for unseen / undefined roles)\n        self.default_adapter = nn.Sequential(\n            nn.Linear(embed_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, embed_dim),\n            nn.LayerNorm(embed_dim)\n        )\n\n    def forward(self, h_context, role_ids, role_mapping):\n        \"\"\"\n        h_context : (N, D)\n        role_ids  : list/series of textual roles matching role_mapping keys\n        role_mapping : {role_name : idx}\n        \"\"\"\n        outputs = []\n        for i, r in enumerate(role_ids):\n            role_name = None\n            # reverse-map index to string\n            if isinstance(r, (int, np.integer)):\n                # find key by index\n                for k,v in role_mapping.items():\n                    if v == r:\n                        role_name = k\n                        break\n            else:\n                role_name = r\n\n            if role_name in self.adapters:\n                out = self.adapters[role_name](h_context[i])\n            else:\n                out = self.default_adapter(h_context[i])\n            outputs.append(out)\n\n        return torch.stack(outputs, dim=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:21:52.788829Z","iopub.execute_input":"2025-11-23T19:21:52.789043Z","iopub.status.idle":"2025-11-23T19:21:52.809149Z","shell.execute_reply.started":"2025-11-23T19:21:52.789026Z","shell.execute_reply":"2025-11-23T19:21:52.808542Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# ----------------------------\n# Helpers: time embeddings\n# ----------------------------\nclass TimeEmbedding(nn.Module):\n    \"\"\"\n    Sinusoidal + learned projection for tau in [0,1].\n    \"\"\"\n    def __init__(self, emb_dim=64, n_freq=8):\n        super().__init__()\n        self.n_freq = n_freq\n        self.proj = nn.Linear(2*n_freq, emb_dim)\n\n    def forward(self, tau):  # tau: (P, T) in [0,1]\n        P, T = tau.shape\n        device = tau.device\n        # [P, T, 2*n_freq]\n        freqs = torch.arange(self.n_freq, device=device).float()  # 0..n-1\n        ang = tau.unsqueeze(-1) * (2.0 * np.pi * (freqs + 1.0))   # avoid 0 freq\n        sin = torch.sin(ang)\n        cos = torch.cos(ang)\n        feats = torch.cat([sin, cos], dim=-1)                     # (P, T, 2*n_freq)\n        return self.proj(feats)                                   # (P, T, emb_dim)\n\n\n# ----------------------------\n# Two-stream decoder\n# ----------------------------\nclass TwoStreamDecoder(nn.Module):\n    \"\"\"\n    Stream A (Goal-drift): drives motion toward (ball_land_x, ball_land_y).\n    Stream B (Interaction correction): local evasive/collision adjustments from context.\n\n    Inputs per play:\n      h_role: (P, D)     role-specific embeddings from 3.3\n      goal_feat: (P, G)  per-player goal features [dx0, dy0, dist0, ux, uy]\n      tau_seq: (P, T)    time-to-land values in [0,1] per player\n      horizon: (P,) long per-player num_frames_output (1..N_max)\n    Outputs:\n      dxy: (P, T, 2)     residuals Œîx,Œîy relative to last input frame\n      mask: (P, T)       1 within horizon, 0 after\n    \"\"\"\n    def __init__(self, d_model=128, time_dim=64, goal_dim=5, hidden=256, N_max=30):\n        super().__init__()\n        self.goal_dim = goal_dim\n        self.N_max = N_max\n        self.time_emb = TimeEmbedding(emb_dim=time_dim, n_freq=8)\n\n        inA = d_model + time_dim + goal_dim\n        inB = d_model + time_dim\n\n        # Stream A: smooth drift toward goal\n        self.streamA = nn.Sequential(\n            nn.Linear(inA, hidden),\n            nn.ReLU(),\n            nn.Linear(hidden, hidden),\n            nn.ReLU(),\n            nn.Linear(hidden, 2)  # Œîx, Œîy per step\n        )\n\n        # Stream B: local interaction correction\n        self.streamB = nn.Sequential(\n            nn.Linear(inB, hidden),\n            nn.ReLU(),\n            nn.Linear(hidden, hidden),\n            nn.ReLU(),\n            nn.Linear(hidden, 2)\n        )\n\n    def forward(self, h_role, goal_feat, tau_seq, horizon):\n        \"\"\"\n        h_role:   (P, D)\n        goal_feat:(P, 5)  = [dx0, dy0, dist0, ux, uy]\n        tau_seq:  (P, T)\n        horizon:  (P,)\n        \"\"\"\n        P, D = h_role.shape\n        T = tau_seq.shape[1]\n\n        # ‚úÖ Allow variable horizon lengths (for curriculum training)\n        if T != self.N_max:\n            # ensure consistent device, dtype, and leading dimension P\n            pad_len = max(self.N_max - T, 0)\n            if pad_len > 0:\n                pad = torch.ones(\n                    (P, pad_len),\n                    dtype=tau_seq.dtype,\n                    device=tau_seq.device\n                )\n                tau_seq = torch.cat([tau_seq, pad], dim=1)\n            elif T > self.N_max:\n                tau_seq = tau_seq[:, :self.N_max]\n            T = self.N_max\n\n\n        # time embedding\n        t_emb = self.time_emb(tau_seq)             # (P, T, time_dim)\n\n        # expand static inputs across time\n        h_rep = h_role.unsqueeze(1).expand(P, T, D)        # (P, T, D)\n        g_rep = goal_feat.unsqueeze(1).expand(P, T, goal_feat.size(1))  # (P, T, 5)\n\n        # stream A: goal drift\n        a_in = torch.cat([h_rep, t_emb, g_rep], dim=-1)    # (P, T, D+time_dim+5)\n        dA = self.streamA(a_in)                            # (P, T, 2)\n\n        # stream B: interaction correction\n        b_in = torch.cat([h_rep, t_emb], dim=-1)           # (P, T, D+time_dim)\n        dB = self.streamB(b_in)                            # (P, T, 2)\n\n        dxy = dA + dB                                      # (P, T, 2)\n\n        # horizon mask: 1..H_i active\n        device = h_role.device\n        t_idx = torch.arange(T, device=device).unsqueeze(0).expand(P, T)  # 0..T-1\n        mask = (t_idx < horizon.unsqueeze(1)).float()                     # (P, T)\n\n        return dxy, mask\n\n\n# ----------------------------\n# Per-play tensor builder\n# ----------------------------\ndef prepare_play_decoder_inputs(play_graph_nodes: pd.DataFrame,\n                                df_in_norm: pd.DataFrame,\n                                game_id: int, play_id: int,\n                                N_max: int = 30,\n                                device: str = \"cpu\"):\n    \"\"\"\n    Builds inputs for TwoStreamDecoder from one play.\n\n    Returns:\n      x0y0:      (P, 2) last input frame positions (for later reconstruction)\n      h0_goal:   (P, 5) [dx0, dy0, dist0, ux, uy]\n      tau_seq:   (P, N_max) tau = t / num_frames_output (clipped to 1)\n      horizon:   (P,)  long\n      (Plus convenience dict with ball_land per play)\n    \"\"\"\n    nodes = play_graph_nodes.reset_index(drop=True).copy()  # needs columns: nfl_id,x,y,player_role,etc.\n\n    # last input position per player is already in nodes['x','y'] from 1.3 throw-frame snapshot\n    x0y0 = torch.tensor(nodes[[\"x\", \"y\"]].to_numpy(), dtype=torch.float32, device=device)  # (P,2)\n\n    # ball landing (per play) from df_in_norm (any row of this play has same ball_land)\n    play_rows = df_in_norm[(df_in_norm.game_id == game_id) & (df_in_norm.play_id == play_id)]\n    bx = float(play_rows[\"ball_land_x\"].iloc[-1])\n    by = float(play_rows[\"ball_land_y\"].iloc[-1])\n\n    # goal vector at throw\n    dx0 = torch.tensor((bx - nodes[\"x\"]).to_numpy(), dtype=torch.float32, device=device)\n    dy0 = torch.tensor((by - nodes[\"y\"]).to_numpy(), dtype=torch.float32, device=device)\n    dist0 = torch.sqrt(dx0**2 + dy0**2) + 1e-6\n    ux = dx0 / dist0\n    uy = dy0 / dist0\n    h0_goal = torch.stack([dx0, dy0, dist0, ux, uy], dim=-1)  # (P,5)\n\n    # per-player horizon from input table\n    # num_frames_output is per (game,play,nfl). Take the last input row per player.\n    horizon_np = (\n        play_rows.sort_values([\"nfl_id\",\"frame_id\"])\n                 .groupby(\"nfl_id\")[\"num_frames_output\"]\n                 .last()\n                 .reindex(nodes[\"nfl_id\"])\n                 .fillna(0).to_numpy(dtype=np.int64)\n    )\n    horizon = torch.tensor(np.minimum(horizon_np, N_max), dtype=torch.long, device=device)  # (P,)\n\n    # tau sequence per player (P, T)\n    T = N_max\n    t_grid = torch.arange(1, T+1, device=device).float().unsqueeze(0).expand(len(nodes), T)  # 1..T\n    denom = torch.clamp(horizon.unsqueeze(1).float(), min=1.0)\n    tau_seq = torch.clamp(t_grid / denom, max=1.0)  # (P,T) in [0,1]\n\n    meta = dict(ball_land=(bx, by))\n    return x0y0, h0_goal, tau_seq, horizon, meta","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:21:52.809837Z","iopub.execute_input":"2025-11-23T19:21:52.810023Z","iopub.status.idle":"2025-11-23T19:21:52.830377Z","shell.execute_reply.started":"2025-11-23T19:21:52.810008Z","shell.execute_reply":"2025-11-23T19:21:52.829637Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def normalize_output_like_input(df_out: pd.DataFrame, df_in: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Flip output x for left plays and center y, using play_direction from input.\"\"\"\n    df_out = df_out.copy()\n    dir_map = (df_in[[\"game_id\",\"play_id\",\"play_direction\"]]\n               .drop_duplicates()\n               .assign(is_left=lambda d: d[\"play_direction\"].str.lower()==\"left\")\n               .drop(columns=\"play_direction\"))\n    df_out = df_out.merge(dir_map, on=[\"game_id\",\"play_id\"], how=\"left\")\n    df_out.loc[df_out[\"is_left\"]==True, \"x\"] = 120 - df_out.loc[df_out[\"is_left\"]==True, \"x\"]\n    df_out[\"y\"] = df_out[\"y\"] - 26.65\n    return df_out.drop(columns=[\"is_left\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:21:52.831078Z","iopub.execute_input":"2025-11-23T19:21:52.831284Z","iopub.status.idle":"2025-11-23T19:21:52.848204Z","shell.execute_reply.started":"2025-11-23T19:21:52.831268Z","shell.execute_reply":"2025-11-23T19:21:52.847479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def precompute_graph_tensors(graphs, df_in_norm, N_max=30):\n    graphs_fast = {}\n\n    for (gid, pid), g in graphs.items():\n\n        nodes = g[\"nodes\"].sort_values(\"nfl_id\").reset_index(drop=True)\n        edges = g[\"edges\"]\n\n        player_ids = nodes[\"nfl_id\"].tolist()\n        P = len(player_ids)\n\n        # -------- node xy --------\n        node_xy = torch.tensor(nodes[[\"x\",\"y\"]].values, dtype=torch.float32)\n\n        # -------- roles ----------\n        roles = nodes[\"player_role\"].tolist()\n\n        # -------- edges ----------\n        id_new = {nid:i for i,nid in enumerate(player_ids)}\n        edges = edges[edges[\"src_id\"].isin(id_new) & edges[\"dst_id\"].isin(id_new)]\n\n        src_idx = edges[\"src_id\"].map(id_new).to_numpy()\n        dst_idx = edges[\"dst_id\"].map(id_new).to_numpy()\n\n        edge_index = torch.tensor([src_idx, dst_idx], dtype=torch.long)\n        edge_attr  = torch.tensor(\n            edges[[\"dx\",\"dy\",\"dvx\",\"dvy\",\"dist\",\"dv\",\"cos_bear\",\"sin_bear\",\"ally_flag\"]]\n            .to_numpy(np.float32)\n        )\n\n        # -------- global context --------\n        global_ctx = torch.tensor([\n            nodes[\"x\"].mean(),\n            nodes[\"y\"].mean(),\n            0.42\n        ], dtype=torch.float32)\n\n        # -------- PRECOMPUTE DECODER INPUTS (goal_feat, tau_seq, horizon) --------\n        x0y0, goal_feat, tau_seq, horizon, meta = prepare_play_decoder_inputs(\n            nodes, df_in_norm, gid, pid, N_max=N_max, device=\"cpu\"\n        )\n        # x0y0 should match node_xy; we keep node_xy as-is\n\n        graphs_fast[(gid,pid)] = {\n            \"player_ids\": player_ids,\n            \"node_xy\": node_xy,              # (P,2)\n            \"roles\": roles,                  # list len P\n            \"edge_index\": edge_index,        # (2,E)\n            \"edge_attr\": edge_attr,          # (E,9)\n            \"global_ctx\": global_ctx,        # (3,)\n            \"goal_feat\": goal_feat,          # (P,5)\n            \"tau_seq\": tau_seq,              # (P,N_max)\n            \"horizon\": horizon,              # (P,)\n        }\n\n    return graphs_fast\n    \n# graphs_fast = precompute_graph_tensors(graphs, df_out_norm, df_in_norm, N_max=30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:21:52.850270Z","iopub.execute_input":"2025-11-23T19:21:52.850461Z","iopub.status.idle":"2025-11-23T19:21:52.862853Z","shell.execute_reply.started":"2025-11-23T19:21:52.850447Z","shell.execute_reply":"2025-11-23T19:21:52.862333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# üîß Utilities / Seeding\n# =========================\nimport os, random, math\nimport numpy as np\nimport torch\nimport time\nfrom torch import nn\nfrom torch.optim import AdamW\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\nfrom contextlib import nullcontext\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# =========================================================\n# üß† End-to-end model wrapper (enc + GAT + role adapters + dec)\n# =========================================================\nclass End2EndModel(nn.Module):\n    def __init__(self, in_dim=8, embed_dim=128, d_model=128, time_dim=64, goal_dim=5,\n                 hidden=256, N_max=30, gat_edge_dim=9, gat_heads=4, gat_layers=2,\n                 role_names=(\"Targeted Receiver\", \"Defensive Coverage\", \"Passer\", \"Other Route Runner\")):\n        super().__init__()\n        # Keep param count ~3‚Äì5M by modest dims\n        self.encoder = TemporalTransformer(in_dim=in_dim, d_model=embed_dim)\n        self.spatial = SpatialTransformer(d_model=embed_dim)\n        self.adapters = RoleSpecificAdapters(embed_dim=embed_dim, hidden_dim=embed_dim,\n                                             role_names=list(role_names))\n        self.decoder = TwoStreamDecoder(d_model=embed_dim, time_dim=time_dim,\n                                        goal_dim=goal_dim, hidden=hidden, N_max=N_max)\n        self.role_names = list(role_names)\n        self.role_map = {r:i for i,r in enumerate(self.role_names)}\n        self.N_max = N_max\n\n    def forward_batch(self, batch, N_max_curr):\n        \"\"\"\n        batch: dict from play_collate\n        Processes all players from all plays in one shot.\n        \"\"\"\n        # unpack & move to device\n        x_hist   = batch[\"x_hist\"].to(DEVICE).float()          # (P_tot,K,F)\n        node_xy  = batch[\"node_xy\"].to(DEVICE).float()         # (P_tot,2)\n        edge_index = batch[\"edge_index\"].to(DEVICE).long()     # (2,E_tot)\n        edge_attr  = batch[\"edge_attr\"].to(DEVICE).float()     # (E_tot,9)\n        goal_feat  = batch[\"goal_feat\"].to(DEVICE).float()     # (P_tot,5)\n        tau_seq    = batch[\"tau_seq\"][:, :N_max_curr].to(DEVICE).float()  # (P_tot,T)\n        horizon    = torch.clamp(batch[\"horizon\"], max=N_max_curr).to(DEVICE).long()  # (P_tot,)\n        global_ctx = batch[\"global_ctx\"].to(DEVICE).float()    # (3,)\n        roles      = batch[\"roles\"]                            # list len P_tot\n\n        h_nodes = self.encoder(x_hist)            # (P,D)\n        h_ctx = self.spatial(h_nodes, edge_index, edge_attr)\n\n        # role adapters\n        h_role = self.adapters(h_ctx, roles, self.role_map)    # (P_tot,D)\n\n        # decoder\n        dxy, mask = self.decoder(h_role, goal_feat, tau_seq, horizon)  # (P_tot,T,2),(P_tot,T)\n\n        xy_pred = node_xy.unsqueeze(1) + torch.cumsum(dxy, dim=1)\n        xy_pred = xy_pred * mask.unsqueeze(-1)\n\n        return xy_pred, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:21:52.863589Z","iopub.execute_input":"2025-11-23T19:21:52.863836Z","iopub.status.idle":"2025-11-23T19:21:52.883384Z","shell.execute_reply.started":"2025-11-23T19:21:52.863815Z","shell.execute_reply":"2025-11-23T19:21:52.882603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def unnormalize_field_direction(preds: pd.DataFrame, raw_input: pd.DataFrame) -> pd.DataFrame:\n    # raw_input has original play_direction\n    dir_map = (\n        raw_input[[\"game_id\",\"play_id\",\"play_direction\"]]\n        .drop_duplicates()\n        .assign(is_left=lambda d: d[\"play_direction\"].str.lower()==\"left\")\n        .drop(columns=\"play_direction\")\n    )\n    out = preds.merge(dir_map, on=[\"game_id\",\"play_id\"], how=\"left\")\n    out[\"y\"] = out[\"y\"] + 26.65\n    mask_left = out[\"is_left\"] == True\n    out.loc[mask_left, \"x\"] = 120 - out.loc[mask_left, \"x\"]\n\n    return out.drop(columns=[\"is_left\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:21:52.884064Z","iopub.execute_input":"2025-11-23T19:21:52.884308Z","iopub.status.idle":"2025-11-23T19:21:52.900998Z","shell.execute_reply.started":"2025-11-23T19:21:52.884292Z","shell.execute_reply":"2025-11-23T19:21:52.900428Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport polars as pl\nimport torch\nimport numpy as np\nfrom sklearn.neighbors import NearestNeighbors\n\nfrom torch import nn\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = End2EndModel(\n    in_dim=8, embed_dim=128, d_model=128, time_dim=64, goal_dim=5, hidden=256, N_max=30\n).to(DEVICE)\n\n# Load weights from dataset you attached\nmodel.load_state_dict(torch.load(\"/kaggle/input/final-model-seed3-stt/pytorch/default/1/final_model_seed3_stt.pt\", map_location=DEVICE))\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:21:52.901831Z","iopub.execute_input":"2025-11-23T19:21:52.902064Z","iopub.status.idle":"2025-11-23T19:21:53.702386Z","shell.execute_reply.started":"2025-11-23T19:21:52.902040Z","shell.execute_reply":"2025-11-23T19:21:53.701687Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict(test: pl.DataFrame, test_input: pl.DataFrame) -> pd.DataFrame:\n    \"\"\"Kaggle will call this repeatedly per timestep\"\"\"\n\n    df = test_input.to_pandas()\n    df = normalize_field_direction(df)\n\n    df = df.sort_values([\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"])\n    df[\"vx\"] = df.groupby([\"game_id\",\"play_id\",\"nfl_id\"])[\"x\"].diff().fillna(0)\n    df[\"vy\"] = df.groupby([\"game_id\",\"play_id\",\"nfl_id\"])[\"y\"].diff().fillna(0)\n\n    # # accelerations\n    # df[\"ax\"] = df.groupby([\"game_id\",\"play_id\",\"nfl_id\"])[\"vx\"].diff().fillna(0)\n    # df[\"ay\"] = df.groupby([\"game_id\",\"play_id\",\"nfl_id\"])[\"vy\"].diff().fillna(0)\n    \n    # # delta speed\n    # df[\"ds\"] = df.groupby([\"game_id\",\"play_id\",\"nfl_id\"])[\"s\"].diff().fillna(0)\n    \n    # # cos/sin of direction\n    # df[\"cos_dir\"] = np.cos(np.radians(df[\"dir\"]))\n    # df[\"sin_dir\"] = np.sin(np.radians(df[\"dir\"]))\n    \n    # # normalized frame index\n    # df[\"frame_norm\"] = (\n    #     df.groupby([\"game_id\",\"play_id\",\"nfl_id\"])[\"frame_id\"]\n    #       .transform(lambda x: x / x.max())\n    # )\n\n    # Build graph for this play\n    graphs = build_interaction_graphs(df, K=6)\n    (gid, pid), graph = next(iter(graphs.items()))\n    nodes = graph[\"nodes\"].copy()\n    \n    graphs_fast = precompute_graph_tensors(\n        {(gid, pid): graph},\n        df_in_norm=df,\n        N_max=30\n    )\n    G = graphs_fast[(gid, pid)]\n\n    # Fill missing columns\n    for c in [\"vx\",\"vy\",\"s\",\"a\",\"dir\",\"o\"]:\n        if c not in nodes.columns:\n            nodes[c] = 0.0\n\n    # Build REAL history from test_input\n    # ======================================================\n    K_hist = 10\n    features = [\"x\",\"y\",\"vx\",\"vy\",\"s\",\"a\",\"dir\",\"o\"]\n    \n    # compute vx/vy from df\n    nodes = nodes.sort_values(\"nfl_id\").reset_index(drop=True)\n    group = df[df[\"nfl_id\"].isin(nodes[\"nfl_id\"])]\n    \n    # extract last K frames per player\n    hist_list = []\n    for nid in nodes[\"nfl_id\"]:\n        g = group[group[\"nfl_id\"] == nid].sort_values(\"frame_id\")\n        g[\"vx\"] = g[\"x\"].diff().fillna(0)\n        g[\"vy\"] = g[\"y\"].diff().fillna(0)\n        # pad if fewer than K frames\n        tail = g[features].to_numpy(np.float32)[-K_hist:]\n        if tail.shape[0] < K_hist:\n            pad = np.repeat(tail[:1], K_hist - tail.shape[0], axis=0)\n            tail = np.vstack([pad, tail])\n        hist_list.append(tail)\n        \n    x_hist = torch.tensor(np.stack(hist_list, axis=0), device=DEVICE)\n\n    # Play + player info\n    gid = int(df[\"game_id\"].iloc[0])\n    pid = int(df[\"play_id\"].iloc[0])\n    player_ids = G[\"player_ids\"]\n\n    # ----------------------------------------------------------\n    # 4. Build batch for forward_batch() (NOT forward_one_play)\n    # ----------------------------------------------------------\n    batch = {\n        \"x_hist\":    x_hist,                       # (P,K,F)\n        \"node_xy\":   G[\"node_xy\"].to(DEVICE),      # (P,2)\n        \"edge_index\":G[\"edge_index\"].to(DEVICE),   # (2,E)\n        \"edge_attr\": G[\"edge_attr\"].to(DEVICE),    # (E,9)\n        \"global_ctx\":G[\"global_ctx\"].to(DEVICE),   # (3,)\n        \"goal_feat\": G[\"goal_feat\"].to(DEVICE),    # (P,5)\n        \"tau_seq\":   G[\"tau_seq\"].to(DEVICE),      # (P,30)\n        \"horizon\":   G[\"horizon\"].to(DEVICE),      # (P,)\n        \"roles\":     G[\"roles\"],                   # list len P\n    }\n\n    # ----------------------------------------------------------\n    # 5. Run model forward\n    # ----------------------------------------------------------\n    with torch.no_grad():\n        xy_pred, mask = model.forward_batch(batch, N_max_curr=30)\n\n    xy_pred = xy_pred.cpu().numpy()\n\n    # ================================\n    # Ensemble: average predictions\n    # ================================\n    # preds_list = []\n    \n    # with torch.no_grad():\n    #     for m in models:\n    #         out, mask = m.forward_batch(batch, N_max_curr=30)\n    #         preds_list.append(out.cpu())\n    \n    # # Stack ‚Üí (3, P, 30, 2)\n    # preds_tensor = torch.stack(preds_list, dim=0)\n    \n    # # Mean over models ‚Üí (P, 30, 2)\n    # xy_pred = preds_tensor.mean(dim=0).numpy()\n\n    preds = pd.DataFrame({\n        \"nfl_id\": player_ids,\n        \"x\": xy_pred[:, 0, 0],  # next-frame prediction\n        \"y\": xy_pred[:, 0, 1],\n    })\n\n    # Align to `test` shape\n    test_pd = test.to_pandas()\n    raw_input_pd = test_input.to_pandas()\n    \n    # Attach original IDs for inversion\n    preds = preds.merge(\n        raw_input_pd[[\"game_id\",\"play_id\",\"nfl_id\"]].drop_duplicates(),\n        on=\"nfl_id\",\n        how=\"left\"\n    )\n    \n    # Undo field normalization using original, unnormalized features\n    preds = unnormalize_field_direction(preds, raw_input_pd)\n    \n    merged = test_pd.merge(preds, on=\"nfl_id\", how=\"left\")\n\n    # Fill missing predictions safely (e.g., players filtered out)\n    merged[\"x\"] = merged[\"x\"].fillna(60.0)\n    merged[\"y\"] = merged[\"y\"].fillna(0.0)\n    \n    # ‚úÖ Diagnostic print for local gateway runs\n    print(f\"‚úÖ Play {gid}-{pid}: expected {len(test_pd)} rows, predicted {len(merged)}\")\n\n    return pl.DataFrame(merged[[\"x\", \"y\"]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:21:53.703113Z","iopub.execute_input":"2025-11-23T19:21:53.703460Z","iopub.status.idle":"2025-11-23T19:21:53.717767Z","shell.execute_reply.started":"2025-11-23T19:21:53.703441Z","shell.execute_reply":"2025-11-23T19:21:53.717120Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kaggle_evaluation.nfl_inference_server\n\ninference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n\nif os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(('/kaggle/input/nfl-big-data-bowl-2026-prediction/',))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:21:53.718459Z","iopub.execute_input":"2025-11-23T19:21:53.718717Z","iopub.status.idle":"2025-11-23T19:22:05.872187Z","shell.execute_reply.started":"2025-11-23T19:21:53.718683Z","shell.execute_reply":"2025-11-23T19:22:05.871584Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}